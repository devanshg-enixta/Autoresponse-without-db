{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "from itertools import *\n",
    "import os,re,sys\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all.txt ---->\n",
      "appearance.txt ---->\n",
      "color.txt ---->\n",
      "condition_of_product.txt ---->\n",
      "convienience.txt ---->\n",
      "information.txt ---->\n",
      "shelf_life.txt ---->\n",
      "sizing.txt ---->\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree('new_fined_grained_phrases_sentiment_pedigree/')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('new_fined_grained_phrases_sentiment_pedigree/')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('new_fined_grained_phrases_sentiment_pedigree/aspects')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "health_impact =[]\n",
    "appearance=[]\n",
    "information=[]\n",
    "quality=[]\n",
    "convienience=[]\n",
    "color=[]\n",
    "others=[]\n",
    "#smell=[]\n",
    "condition_of_product=[]\n",
    "food_eaten=[]\n",
    "#taste=[]\n",
    "serving_food=[]\n",
    "nutrition_ingredients =[]\n",
    "pricing=[]\n",
    "sizing=[]\n",
    "shelf_life=[]\n",
    "damage=[]\n",
    "delivery=[]\n",
    "offers_n_discounts=[]\n",
    "\n",
    "for file in glob.glob('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/*'):\n",
    "    file =file.replace('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/','')\n",
    "   # print file\n",
    "    if 'body' in file or 'health' in file or 'dental' in file or 'death' in file or 'effect' in file:\n",
    "        f= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        health_impact.append(list(f.readlines()))\n",
    "    elif 'offer' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        offers_n_discounts.append(list(x.readlines()))\n",
    "    elif 'delivery' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        delivery.append(list(x.readlines()))\n",
    "    elif 'food-cond' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        condition_of_product.append(list(x.readlines()))\n",
    "    elif 'product-cond' in file or 'warrant' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        shelf_life.append(list(x.readlines()))\n",
    "        \n",
    "    elif 'intake' in file or 'pack' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        convienience.append(list(x.readlines()))\n",
    "    elif 'infest' in file:\n",
    "        print file,'here ewiuaskrgjfbdjnc,mwea,sfm'\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        quality.append(list(x.readlines()))\n",
    "    elif 'display' in file or 'dimensio' in file or 'dura' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        information.append(list(x.readlines()))\n",
    "    elif 'eata' in file :\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        appearance.append(list(x.readlines()))\n",
    "    elif 'ingredient' in file or 'nutri' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        nutrition_ingredients.append(list(x.readlines()))\n",
    "    elif 'shape' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        sizing.append(list(x.readlines()))\n",
    "    elif 'vf' in file or 'pri' in file:\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        pricing.append(list(x.readlines()))\n",
    "    elif 'style' in file :\n",
    "        x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "        color.append(list(x.readlines()))\n",
    "    \n",
    "    else:\n",
    "        #temp = open(file,'r+')\n",
    "        if os.stat('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file).st_size != 0 :\n",
    "            if 'taste' in file or 'dog-user-breed' in file  or 'smell' in file:\n",
    "                shutil.copyfile('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file, 'new_fined_grained_phrases_sentiment_pedigree/aspects/'+file)\n",
    "            else:\n",
    "                x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects/'+file,'r+')\n",
    "                others.append(list(x.readlines()))\n",
    "                print file,\"---->\"\n",
    "\n",
    "################### files names###############\n",
    "path = os.getcwd()+''\n",
    "health = open('new_fined_grained_phrases_sentiment_pedigree/aspects/health_impact.txt','a')\n",
    "app=open('new_fined_grained_phrases_sentiment_pedigree/aspects/appearance.txt','a+')\n",
    "info=open('new_fined_grained_phrases_sentiment_pedigree/aspects/information.txt','a+')\n",
    "qual=open('new_fined_grained_phrases_sentiment_pedigree/aspects/quality.txt','a+')\n",
    "conv=open('new_fined_grained_phrases_sentiment_pedigree/aspects/convienience.txt','a+')\n",
    "col=open('new_fined_grained_phrases_sentiment_pedigree/aspects/color.txt','a+')\n",
    "#smell=[]\n",
    "cop=open('new_fined_grained_phrases_sentiment_pedigree/aspects/condition_of_product.txt','a+')\n",
    "food=open('new_fined_grained_phrases_sentiment_pedigree/aspects/food_eaten.txt','a+')\n",
    "#taste=[]\n",
    "serving=open('new_fined_grained_phrases_sentiment_pedigree/aspects/serving_food.txt','a+')\n",
    "nutrition =open('new_fined_grained_phrases_sentiment_pedigree/aspects/nutrition_ingredientst.txt','a+')\n",
    "pric=open('new_fined_grained_phrases_sentiment_pedigree/aspects/pricing.txt','a+')\n",
    "siz=open('new_fined_grained_phrases_sentiment_pedigree/aspects/sizing.txt','a+')\n",
    "shelf=open('new_fined_grained_phrases_sentiment_pedigree/aspects/shelf_life.txt','a+')\n",
    "dam=open('new_fined_grained_phrases_sentiment_pedigree/aspects/damage.txt','a+')\n",
    "deli=open('new_fined_grained_phrases_sentiment_pedigree/aspects/delivery.txt','a+')\n",
    "offers=open('new_fined_grained_phrases_sentiment_pedigree/aspects/offers_n_discounts.txt','a+')\n",
    "al=open('new_fined_grained_phrases_sentiment_pedigree/aspects/all.txt','a+')\n",
    "\n",
    "##################code #######################                \n",
    "health_impact=list(chain.from_iterable(health_impact))\n",
    "health_impact=[i.replace('\\n','').split('\\r', 1)[0] for i in health_impact]\n",
    "health_impact = filter(None, health_impact)\n",
    "health.write(\"\\n\".join(health_impact))\n",
    "health.close()\n",
    "\n",
    "offers_n_discounts=list(chain.from_iterable(offers_n_discounts))\n",
    "offers_n_discounts = [words for segments in offers_n_discounts for words in segments.split('\\r')]\n",
    "offers_n_discounts = filter(None, offers_n_discounts)\n",
    "offers.write(\"\\n\".join(offers_n_discounts))\n",
    "offers.close()\n",
    "\n",
    "delivery=list(chain.from_iterable(delivery))\n",
    "delivery=[i.replace('\\n','').split('\\r', 1)[0] for i in delivery]\n",
    "delivery= filter(None, delivery)\n",
    "deli.write(\"\\n\".join(delivery))\n",
    "deli.close()\n",
    "\n",
    "condition_of_product=list(chain.from_iterable(condition_of_product))\n",
    "condition_of_product=[i.replace('\\n','').split('\\r', 1)[0] for i in condition_of_product]\n",
    "condition_of_product= filter(None, condition_of_product)\n",
    "cop.write(\"\\n\".join(condition_of_product))\n",
    "cop.close()\n",
    "\n",
    "shelf_life=list(chain.from_iterable(shelf_life))\n",
    "shelf_life = [words for segments in shelf_life for words in segments.replace('\\n','').split('\\r')]\n",
    "shelf_life = filter(None, shelf_life)\n",
    "shelf_life = [i for i in shelf_life if 'condition' not in i]\n",
    "shelf.write(\"\\n\".join(shelf_life))\n",
    "shelf.close()\n",
    "\n",
    "convienience=list(chain.from_iterable(convienience))\n",
    "convienience = [words for segments in convienience for words in segments.replace('\\n','').split('\\r')]\n",
    "convienience  = filter(None, convienience )\n",
    "conv.write(\"\\n\".join(convienience))\n",
    "conv.close()\n",
    "\n",
    "quality=list(chain.from_iterable(quality))\n",
    "quality = [words for segments in quality for words in segments.replace('\\n','').split('\\r')]\n",
    "quality = filter(None, quality)\n",
    "qual.write(\"\\n\".join(quality))\n",
    "qual.close()\n",
    "\n",
    "information=list(chain.from_iterable(information))\n",
    "information = [words for segments in information for words in segments.replace('\\n','').split('\\r')]\n",
    "information = filter(None, information)\n",
    "info.write(\"\\n\".join(information))\n",
    "info.close()\n",
    "\n",
    "appearance=list(chain.from_iterable(appearance))\n",
    "appearance = [words for segments in appearance for words in segments.replace('\\n','').split('\\r')]\n",
    "appearance= filter(None, appearance)\n",
    "app.write(\"\\n\".join(appearance))\n",
    "app.close()\n",
    "\n",
    "nutrition_ingredients=list(chain.from_iterable(nutrition_ingredients))\n",
    "nutrition_ingredients = [words for segments in nutrition_ingredients for words in segments.replace('\\n','').split('\\r')]\n",
    "nutrition_ingredients = filter(None, nutrition_ingredients)\n",
    "nutrition.write(\"\\n\".join(nutrition_ingredients))\n",
    "nutrition.close()\n",
    "\n",
    "sizing=list(chain.from_iterable(sizing))\n",
    "sizing = [words for segments in sizing for words in segments.replace('\\n','').split('\\r')]\n",
    "sizing = filter(None, sizing)\n",
    "siz.write(\"\\n\".join(sizing))\n",
    "siz.close()\n",
    "\n",
    "pricing=list(chain.from_iterable(pricing))\n",
    "pricing = [words for segments in pricing for words in segments.replace('\\n','').split('\\r')]\n",
    "pricing = filter(None, pricing)\n",
    "pric.write(\"\\n\".join(pricing))\n",
    "pric.close()\n",
    "\n",
    "color=list(chain.from_iterable(color))\n",
    "color = [words for segments in color for words in segments.replace('\\n','').split('\\r')]\n",
    "color = filter(None, color)\n",
    "col.write(\"\\n\".join(color))\n",
    "col.close()\n",
    "\n",
    "others=list(chain.from_iterable(others))\n",
    "others = [words for segments in others for words in segments.replace('\\n','').split('\\r')]\n",
    "others  = filter(None, others )\n",
    "al.write(\"\\n\".join(others))\n",
    "al.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color_negative.txt ---->\n",
      "convienience_negative.txt ---->\n",
      "information_negative.txt ---->\n",
      "others_negative.txt ---->\n",
      "shelf_life_negative.txt ---->\n",
      "appearance_positive.txt ---->\n",
      "color_positive.txt ---->\n",
      "convienience_positive.txt ---->\n",
      "information_positive.txt ---->\n",
      "others_positive.txt ---->\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments')\n",
    "except:\n",
    "    pass\n",
    "def flatten(container):\n",
    "    for i in container:\n",
    "        if isinstance(i, (list,tuple)):\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "        else:\n",
    "            yield i\n",
    "\n",
    "# health_impact =[]\n",
    "# appearance=[]\n",
    "# information=[]\n",
    "# quality=[]\n",
    "# convienience=[]\n",
    "# color=[]\n",
    "# #smell=[]\n",
    "# condition_of_product=[]\n",
    "# food_eaten=[]\n",
    "# #taste=[]\n",
    "# serving_food=[]\n",
    "# nutrition_ingredients =[]\n",
    "# pricing=[]\n",
    "# sizing=[]\n",
    "# shelf_life=[]\n",
    "# damage=[]\n",
    "# delivery=[]\n",
    "# offers_n_discounts=[]\n",
    "# others=[]\n",
    "################### files names###############\n",
    "path = os.getcwd()+''\n",
    "for i in ['negative','positive']:\n",
    "    health_impact =[]\n",
    "    appearance=[]\n",
    "    information=[]\n",
    "    quality=[]\n",
    "    convienience=[]\n",
    "    color=[]\n",
    "    #smell=[]\n",
    "    condition_of_product=[]\n",
    "    food_eaten=[]\n",
    "    #taste=[]\n",
    "    serving_food=[]\n",
    "    nutrition_ingredients =[]\n",
    "    pricing=[]\n",
    "    sizing=[]\n",
    "    shelf_life=[]\n",
    "    damage=[]\n",
    "    delivery=[]\n",
    "    offers_n_discounts=[]\n",
    "    others=[]\n",
    "    health = open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/health_impact_'+i+'.txt','a')\n",
    "    app=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/appearance_'+i+'.txt','a+')\n",
    "    info=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/information_'+i+'.txt','a+')\n",
    "    qual=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/quality_'+i+'.txt','a+')\n",
    "    conv=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/convienience_'+i+'.txt','a+')\n",
    "    col=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/color_'+i+'.txt','a+')\n",
    "    #smell=[]\n",
    "    cop=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/condition_of_product_'+i+'.txt','a+')\n",
    "    food=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/food_eaten_'+i+'.txt','a+')\n",
    "    #taste=[]\n",
    "    serving=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/serving_food_'+i+'.txt','a+')\n",
    "    nutrition =open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/nutrition_ingredientst_'+i+'.txt','a+')\n",
    "    pric=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/pricing_'+i+'.txt','a+')\n",
    "    siz=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/sizing_'+i+'.txt','a+')\n",
    "    shelf=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/shelf_life_'+i+'.txt','a+')\n",
    "    dam=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/damage_'+i+'.txt','a+')\n",
    "    deli=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/delivery_'+i+'.txt','a+')\n",
    "    offers=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/offers_n_discounts_'+i+'.txt','a+')\n",
    "    al=open('new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/others_'+i+'.txt','a+')\n",
    "\n",
    "    ##################code #######################\n",
    "    for file in glob.glob('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/*'+i+'.txt'):\n",
    "        file =file.replace('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/','')\n",
    "        #print file\n",
    "        if 'body' in file or 'health' in file or 'dental' in file or 'death' in file or 'effect' in file:\n",
    "            f= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            health_impact.append(list(f.readlines()))\n",
    "        elif 'offer' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            offers_n_discounts.append(list(x.readlines()))\n",
    "        elif 'delivery' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            delivery.append(list(x.readlines()))\n",
    "        elif 'food-cond' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            condition_of_product.append(list(x.readlines()))\n",
    "        elif 'product-cond' in file or 'warrant' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            shelf_life.append(list(x.readlines()))\n",
    "\n",
    "        elif 'intake' in file or 'pack' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            convienience.append(list(x.readlines()))\n",
    "        elif 'infest' in file or 'qual' in file:\n",
    "            #print file,'here ewiuaskrgjfbdjnc,mwea,sfm'\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            quality.append(list(x.readlines()))\n",
    "        elif 'display' in file or 'dimensio' in file or 'dura' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            information.append(list(x.readlines()))\n",
    "        elif 'eata' in file :\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            appearance.append(list(x.readlines()))\n",
    "        elif 'ingredient' in file or 'nutri' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            nutrition_ingredients.append(list(x.readlines()))\n",
    "        elif 'shape' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            sizing.append(list(x.readlines()))\n",
    "        elif 'vf' in file or 'pri' in file:\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            pricing.append(list(x.readlines()))\n",
    "        elif 'style' in file :\n",
    "            x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "            color.append(list(x.readlines()))\n",
    "\n",
    "        else:\n",
    "            #temp = open(file,'r+')\n",
    "            if os.stat('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file).st_size != 0 :\n",
    "                if 'taste' in file or 'dog-user-breed' in file  or 'smell' in file:\n",
    "                    shutil.copyfile('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file, 'new_fined_grained_phrases_sentiment_pedigree/aspects-sentiments/'+file)\n",
    "                else:\n",
    "                    print file,\"---->\"\n",
    "                    x= open('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/aspects-sentiments/'+file,'r+')\n",
    "                    others.append(list(x.readlines()))\n",
    "    \n",
    "\n",
    "    health_impact=list(flatten(health_impact))\n",
    "    health_impact=[i.replace('\\n','').split('\\r', 1)[0] for i in health_impact]\n",
    "    health_impact = filter(None, health_impact)\n",
    "\n",
    "    health.write(\"\\n\".join(health_impact))\n",
    "    health.close()\n",
    "\n",
    "    offers_n_discounts=list(chain.from_iterable(offers_n_discounts))\n",
    "    offers_n_discounts = [words for segments in offers_n_discounts for words in segments.split('\\r')]\n",
    "    offers_n_discounts = filter(None, offers_n_discounts)\n",
    "    offers.write(\"\\n\".join(offers_n_discounts))\n",
    "    offers.close()\n",
    "\n",
    "    delivery=list(chain.from_iterable(delivery))\n",
    "    delivery=[i.replace('\\n','').split('\\r', 1)[0] for i in delivery]\n",
    "    delivery= filter(None, delivery)\n",
    "    deli.write(\"\\n\".join(delivery))\n",
    "    deli.close()\n",
    "\n",
    "    condition_of_product=list(chain.from_iterable(condition_of_product))\n",
    "    condition_of_product=[i.replace('\\n','').split('\\r', 1)[0] for i in condition_of_product]\n",
    "    condition_of_product= filter(None, condition_of_product)\n",
    "    cop.write(\"\\n\".join(condition_of_product))\n",
    "    cop.close()\n",
    "\n",
    "    shelf_life=list(chain.from_iterable(shelf_life))\n",
    "    shelf_life = [words for segments in shelf_life for words in segments.replace('\\n','').split('\\r')]\n",
    "    shelf_life = [i for i in shelf_life if 'condition' not in i]\n",
    "    shelf_life = filter(None, shelf_life)\n",
    "    shelf.write(\"\\n\".join(shelf_life))\n",
    "    shelf.close()\n",
    "\n",
    "    convienience=list(chain.from_iterable(convienience))\n",
    "    convienience = [words for segments in convienience for words in segments.replace('\\n','').split('\\r')]\n",
    "    convienience  = filter(None, convienience )\n",
    "    conv.write(\"\\n\".join(convienience))\n",
    "    conv.close()\n",
    "\n",
    "    quality=list(chain.from_iterable(quality))\n",
    "    quality = [words for segments in quality for words in segments.replace('\\n','').split('\\r')]\n",
    "    quality = filter(None, quality)\n",
    "    qual.write(\"\\n\".join(quality))\n",
    "    qual.close()\n",
    "\n",
    "    information=list(chain.from_iterable(information))\n",
    "    information = [words for segments in information for words in segments.replace('\\n','').split('\\r')]\n",
    "    information = filter(None, information)\n",
    "    info.write(\"\\n\".join(information))\n",
    "    info.close()\n",
    "\n",
    "    appearance=list(chain.from_iterable(appearance))\n",
    "    appearance = [words for segments in appearance for words in segments.replace('\\n','').split('\\r')]\n",
    "    appearance= filter(None, appearance)\n",
    "    app.write(\"\\n\".join(appearance))\n",
    "    app.close()\n",
    "\n",
    "    nutrition_ingredients=list(chain.from_iterable(nutrition_ingredients))\n",
    "    nutrition_ingredients = [words for segments in nutrition_ingredients for words in segments.replace('\\n','').split('\\r')]\n",
    "    nutrition_ingredients = filter(None, nutrition_ingredients)\n",
    "    nutrition.write(\"\\n\".join(nutrition_ingredients))\n",
    "    nutrition.close()\n",
    "\n",
    "    sizing=list(chain.from_iterable(sizing))\n",
    "    sizing = [words for segments in sizing for words in segments.replace('\\n','').split('\\r')]\n",
    "    sizing = filter(None, sizing)\n",
    "    siz.write(\"\\n\".join(sizing))\n",
    "    siz.close()\n",
    "    \n",
    "    pricing=list(flatten(pricing))\n",
    "    #print pricing\n",
    "    pricing = [words for segments in pricing for words in segments.replace('\\n','').split('\\r')]\n",
    "    pricing = filter(None, pricing)\n",
    "    pric.write(\"\\n\".join(pricing))\n",
    "    pric.close()\n",
    "\n",
    "    color=list(chain.from_iterable(color))\n",
    "    color = [words for segments in color for words in segments.replace('\\n','').split('\\r')]\n",
    "    color = filter(None, color)\n",
    "    col.write(\"\\n\".join(color))\n",
    "    col.close()\n",
    "    \n",
    "    others=list(flatten(others))\n",
    "    others = [words for segments in others for words in segments.replace('\\n','').split('\\r')]\n",
    "    others  = filter(None, others )\n",
    "    al.write(\"\\n\".join(others))\n",
    "    al.close()\n",
    "shutil.copytree('Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters/sentiments', 'new_fined_grained_phrases_sentiment_pedigree/sentiments/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('new_fined_grained_phrases_sentiment_pedigree/domain_words')\n",
    "except:\n",
    "    pass\n",
    "def flatten(container):\n",
    "    for i in container:\n",
    "        if isinstance(i, (list,tuple)):\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "        else:\n",
    "            yield i\n",
    "\n",
    "# health_impact =[]\n",
    "# appearance=[]\n",
    "# information=[]\n",
    "# quality=[]\n",
    "# convienience=[]\n",
    "# color=[]\n",
    "# #smell=[]\n",
    "# condition_of_product=[]\n",
    "# food_eaten=[]\n",
    "# #taste=[]\n",
    "# serving_food=[]\n",
    "# nutrition_ingredients =[]\n",
    "# pricing=[]\n",
    "# sizing=[]\n",
    "# shelf_life=[]\n",
    "# damage=[]\n",
    "# delivery=[]\n",
    "# offers_n_discounts=[]\n",
    "# others=[]\n",
    "################### files names###############\n",
    "path = os.getcwd()+''\n",
    "for i in ['negative','positive']:\n",
    "    health_impact =[]\n",
    "    appearance=[]\n",
    "    information=[]\n",
    "    quality=[]\n",
    "    convienience=[]\n",
    "    color=[]\n",
    "    #smell=[]\n",
    "    condition_of_product=[]\n",
    "    food_eaten=[]\n",
    "    #taste=[]\n",
    "    serving_food=[]\n",
    "    nutrition_ingredients =[]\n",
    "    pricing=[]\n",
    "    sizing=[]\n",
    "    shelf_life=[]\n",
    "    damage=[]\n",
    "    delivery=[]\n",
    "    offers_n_discounts=[]\n",
    "    others=[]\n",
    "    health = open('new_fined_grained_phrases_sentiment_pedigree/domain_words/health_impact_domain_'+i+'.txt','a')\n",
    "    app=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/appearance_domain_'+i+'.txt','a+')\n",
    "    info=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/information_domain_'+i+'.txt','a+')\n",
    "    qual=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/quality_domain_'+i+'.txt','a+')\n",
    "    conv=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/convienience_domain_'+i+'.txt','a+')\n",
    "    col=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/color_domain_'+i+'.txt','a+')\n",
    "    #smell=[]\n",
    "    cop=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/condition_of_product_domain_'+i+'.txt','a+')\n",
    "    food=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/food_eaten_domain_'+i+'.txt','a+')\n",
    "    #taste=[]\n",
    "    serving=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/serving_food_domain_'+i+'.txt','a+')\n",
    "    nutrition =open('new_fined_grained_phrases_sentiment_pedigree/domain_words/nutrition_ingredientst_domain_'+i+'.txt','a+')\n",
    "    pric=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/pricing_domain_'+i+'.txt','a+')\n",
    "    siz=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/sizing_domain_'+i+'.txt','a+')\n",
    "    shelf=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/shelf_life_domain_'+i+'.txt','a+')\n",
    "    dam=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/damage_domain_'+i+'.txt','a+')\n",
    "    deli=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/delivery_domain_'+i+'.txt','a+')\n",
    "    offers=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/offers_n_discounts_domain_'+i+'.txt','a+')\n",
    "    al=open('new_fined_grained_phrases_sentiment_pedigree/domain_words/others_domain_'+i+'.txt','a+')\n",
    "\n",
    "    ##################code #######################\n",
    "    for file in glob.glob('Pedigree_autoresponses/domain_words/*'+i+'.txt'):\n",
    "        file =file.replace('Pedigree_autoresponses/domain_words/','')\n",
    "        #print file\n",
    "        if 'body' in file or 'health' in file or 'dental' in file or 'death' in file or 'effect' in file:\n",
    "            f= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            health_impact.append(list(f.readlines()))\n",
    "        elif 'offer' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            offers_n_discounts.append(list(x.readlines()))\n",
    "        elif 'delivery' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            delivery.append(list(x.readlines()))\n",
    "        elif 'food-cond' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            condition_of_product.append(list(x.readlines()))\n",
    "        elif 'product-cond' in file or 'warrant' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            shelf_life.append(list(x.readlines()))\n",
    "\n",
    "        elif 'intake' in file or 'pack' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            convienience.append(list(x.readlines()))\n",
    "        elif 'infest' in file or 'qual' in file:\n",
    "            #print file,'here ewiuaskrgjfbdjnc,mwea,sfm'\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            quality.append(list(x.readlines()))\n",
    "        elif 'display' in file or 'dimensio' in file or 'dura' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            information.append(list(x.readlines()))\n",
    "        elif 'eata' in file :\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            appearance.append(list(x.readlines()))\n",
    "        elif 'ingredient' in file or 'nutri' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            nutrition_ingredients.append(list(x.readlines()))\n",
    "        elif 'shape' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            sizing.append(list(x.readlines()))\n",
    "        elif 'vf' in file or 'pri' in file:\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            pricing.append(list(x.readlines()))\n",
    "        elif 'style' in file :\n",
    "            x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "            color.append(list(x.readlines()))\n",
    "\n",
    "        else:\n",
    "            #temp = open(file,'r+')\n",
    "            if os.stat('Pedigree_autoresponses/domain_words/'+file).st_size != 0 :\n",
    "                if 'taste' in file or 'dog-user-breed' in file  or 'smell' in file:\n",
    "                    shutil.copyfile('Pedigree_autoresponses/domain_words/'+file, 'new_fined_grained_phrases_sentiment_pedigree/domain_words/'+file)\n",
    "                else:\n",
    "                    print file,\"---->\"\n",
    "                    x= open('Pedigree_autoresponses/domain_words/'+file,'r+')\n",
    "                    others.append(list(x.readlines()))\n",
    "            else:\n",
    "                print file\n",
    "\n",
    "    health_impact=list(flatten(health_impact))\n",
    "    health_impact=[i.replace('\\n','').split('\\r', 1)[0] for i in health_impact]\n",
    "    health_impact = filter(None, health_impact)\n",
    "\n",
    "    health.write(\"\\n\".join(health_impact))\n",
    "    health.close()\n",
    "\n",
    "    offers_n_discounts=list(chain.from_iterable(offers_n_discounts))\n",
    "    offers_n_discounts = [words for segments in offers_n_discounts for words in segments.split('\\r')]\n",
    "    offers_n_discounts = filter(None, offers_n_discounts)\n",
    "    offers.write(\"\\n\".join(offers_n_discounts))\n",
    "    offers.close()\n",
    "\n",
    "    delivery=list(chain.from_iterable(delivery))\n",
    "    delivery=[i.replace('\\n','').split('\\r', 1)[0] for i in delivery]\n",
    "    delivery= filter(None, delivery)\n",
    "    deli.write(\"\\n\".join(delivery))\n",
    "    deli.close()\n",
    "\n",
    "    condition_of_product=list(chain.from_iterable(condition_of_product))\n",
    "    condition_of_product=[i.replace('\\n','').split('\\r', 1)[0] for i in condition_of_product]\n",
    "    condition_of_product= filter(None, condition_of_product)\n",
    "    cop.write(\"\\n\".join(condition_of_product))\n",
    "    cop.close()\n",
    "\n",
    "    shelf_life=list(chain.from_iterable(shelf_life))\n",
    "    shelf_life = [words for segments in shelf_life for words in segments.replace('\\n','').split('\\r')]\n",
    "    shelf_life = [i for i in shelf_life if 'condition' not in i]\n",
    "    shelf_life = filter(None, shelf_life)\n",
    "    shelf.write(\"\\n\".join(shelf_life))\n",
    "    shelf.close()\n",
    "\n",
    "    convienience=list(chain.from_iterable(convienience))\n",
    "    convienience = [words for segments in convienience for words in segments.replace('\\n','').split('\\r')]\n",
    "    convienience  = filter(None, convienience )\n",
    "    conv.write(\"\\n\".join(convienience))\n",
    "    conv.close()\n",
    "\n",
    "    quality=list(chain.from_iterable(quality))\n",
    "    quality = [words for segments in quality for words in segments.replace('\\n','').split('\\r')]\n",
    "    quality = filter(None, quality)\n",
    "    qual.write(\"\\n\".join(quality))\n",
    "    qual.close()\n",
    "\n",
    "    information=list(chain.from_iterable(information))\n",
    "    information = [words for segments in information for words in segments.replace('\\n','').split('\\r')]\n",
    "    information = filter(None, information)\n",
    "    info.write(\"\\n\".join(information))\n",
    "    info.close()\n",
    "\n",
    "    appearance=list(chain.from_iterable(appearance))\n",
    "    appearance = [words for segments in appearance for words in segments.replace('\\n','').split('\\r')]\n",
    "    appearance= filter(None, appearance)\n",
    "    app.write(\"\\n\".join(appearance))\n",
    "    app.close()\n",
    "\n",
    "    nutrition_ingredients=list(chain.from_iterable(nutrition_ingredients))\n",
    "    nutrition_ingredients = [words for segments in nutrition_ingredients for words in segments.replace('\\n','').split('\\r')]\n",
    "    nutrition_ingredients = filter(None, nutrition_ingredients)\n",
    "    nutrition.write(\"\\n\".join(nutrition_ingredients))\n",
    "    nutrition.close()\n",
    "\n",
    "    sizing=list(chain.from_iterable(sizing))\n",
    "    sizing = [words for segments in sizing for words in segments.replace('\\n','').split('\\r')]\n",
    "    sizing = filter(None, sizing)\n",
    "    siz.write(\"\\n\".join(sizing))\n",
    "    siz.close()\n",
    "    \n",
    "    pricing=list(flatten(pricing))\n",
    "    #print pricing\n",
    "    pricing = [words for segments in pricing for words in segments.replace('\\n','').split('\\r')]\n",
    "    pricing = filter(None, pricing)\n",
    "    pric.write(\"\\n\".join(pricing))\n",
    "    pric.close()\n",
    "\n",
    "    color=list(chain.from_iterable(color))\n",
    "    color = [words for segments in color for words in segments.replace('\\n','').split('\\r')]\n",
    "    color = filter(None, color)\n",
    "    col.write(\"\\n\".join(color))\n",
    "    col.close()\n",
    "    \n",
    "    others=list(flatten(others))\n",
    "    others = [words for segments in others for words in segments.replace('\\n','').split('\\r')]\n",
    "    others  = filter(None, others )\n",
    "    al.write(\"\\n\".join(others))\n",
    "    al.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "aspects = path+\"/Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters_old/aspects\"\n",
    "asp_sent = path+\"/Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters_old/aspects-sentiments\"\n",
    "sent_path = path+\"/Pedigree_autoresponses/fine_grained_phrases_pedigree_sentiment_sub_clusters_old/sentiments\"\n",
    "replies_dir = path+\"/Pedigree_autoresponses/responses_sub_clusters/aspect_sentiments_responses\"\n",
    "negation_words_file = \"/Users/devanshg/Desktop/enixta-machine-learning-master/Smaartpulse_Python_Base/data_annotation/negation_words.txt\"\n",
    "questions_file =path+\"/Pedigree_autoresponses/hot_warm_dont_reply_classification/questions_words.txt\"\n",
    "domain = path+\"/Pedigree_autoresponses/domain_words/sentiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "asp = []\n",
    "aspects_location = path+'/Pedigree_autoresponses/hot_warm_dont_reply_classification/'\n",
    "dont_reply_file = open(aspects_location + \"dont-reply.txt\", 'r')\n",
    "fd = (dont_reply_file.readline())\n",
    "for file in glob.glob(aspects+'/*.txt'):\n",
    "    name = file.split('/')[-1]\n",
    "    f = open(file,'rb')\n",
    "    lines =f.readlines()\n",
    "    lines = [words for segments in lines for words in segments.replace('\\n','').split('\\r')]\n",
    "    lines = filter(None, lines)\n",
    "    for line in lines:\n",
    "        if name.split('.')[0].strip() in fd:\n",
    "            row = [1,name.split('.')[0],line.strip(),'','A','sentiment']\n",
    "            asp.append(row)\n",
    "        else:\n",
    "            row = [1,name.split('.')[0],line.strip(),'','A','sentiment']\n",
    "            asp.append(row)\n",
    "\n",
    "for file in glob.glob(asp_sent+'/*.txt'):\n",
    "    name = file.split('/')[-1]\n",
    "    asp_name = name.split('_')[0]\n",
    "    sent  = name.split('_')[-1].split('.')[0]\n",
    "    f = open(file,'rb')\n",
    "    lines =f.readlines()\n",
    "    lines = [words for segments in lines for words in segments.replace('\\n','').split('\\r')]\n",
    "    lines = filter(None, lines)\n",
    "    for line in lines:\n",
    "        if asp_name.strip() in fd:\n",
    "            row = [1,asp_name,line.strip(),sent,'AS','sentiment']\n",
    "            asp.append(row)\n",
    "        else:\n",
    "            row = [1,asp_name,line.strip(),sent,'AS','sentiment']\n",
    "            asp.append(row)\n",
    "\n",
    "for file in glob.glob(domain+'/*.txt'):\n",
    "    name = file.split('/')[-1]\n",
    "    asp_name = name.split('_domain_')[0]\n",
    "    sent  = name.split('_domain_')[-1].split('.')[0]\n",
    "    f = open(file,'rb')\n",
    "    lines =f.readlines()\n",
    "    lines = [words for segments in lines for words in segments.replace('\\n','').split('\\r')]\n",
    "    lines = filter(None, lines)\n",
    "    for line in lines:\n",
    "        row = [1,asp_name,line.strip(),sent,'DW','sentiment']\n",
    "        asp.append(row)\n",
    "\n",
    "asp = pd.DataFrame(asp)\n",
    "asp.columns = ['brand_id','aspect_name','keyword','sentiment_type','lexicon_type','classification_type']\n",
    "asp.to_csv('aspect_related_words.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'AS'], dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asp.lexicon_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "asp = []\n",
    "for file in glob.glob(sent_path+'/*.txt'):\n",
    "    name = file.split('/')[-1]\n",
    "    #print name\n",
    "    f = open(file,'rb')\n",
    "    lines =f.readlines()\n",
    "    lines = [words for segments in (lines) for words in segments.replace('\\n','').split('\\r')]\n",
    "    lines = filter(None, lines)\n",
    "    for line in lines:\n",
    "        row = [str(line.strip()),'S',name.split('.')[0]]\n",
    "        asp.append(row)\n",
    "#print asp\n",
    "name = negation_words_file.split('/')[-1]\n",
    "f = open(negation_words_file,'rb')\n",
    "lines =f.readlines()\n",
    "lines = [words for segments in lines for words in segments.replace('\\n','').split('\\r')]\n",
    "lines = filter(None, lines)\n",
    "for line in lines:\n",
    "    row = [str(line.strip()),'N','negation']\n",
    "    asp.append(row)\n",
    "name = questions_file.split('/')[-1]\n",
    "f = open(questions_file,'rb')\n",
    "lines =f.readlines()\n",
    "lines = [words for segments in lines for words in segments.replace('\\n','').split('\\r')]\n",
    "lines = filter(None, lines)\n",
    "for line in lines:\n",
    "    row = [str(line.strip()),'Q','question']\n",
    "    asp.append(row)\n",
    "asp = pd.DataFrame(asp)\n",
    "asp.columns = ['keyword','keyword_type','sentiment_type']\n",
    "#asp = asp.keyword.astype('str')\n",
    "asp.to_csv('meta_words.txt',sep='~',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body-parts-eyes_negative ---> body-parts-eyes --> negative\n",
      "body-parts-eyes_positive ---> body-parts-eyes --> positive\n",
      "body-parts-muscles_negative ---> body-parts-muscles --> negative\n",
      "body-parts-muscles_positive ---> body-parts-muscles --> positive\n",
      "body-parts-paws_negative ---> body-parts-paws --> negative\n",
      "body-parts-paws_positive ---> body-parts-paws --> positive\n",
      "body-parts-skin_negative ---> body-parts-skin --> negative\n",
      "body-parts-skin_positive ---> body-parts-skin --> positive\n",
      "body-parts_negative ---> body-parts --> negative\n",
      "body-parts_positive ---> body-parts --> positive\n",
      "competitors-others_negative ---> competitors-others --> negative\n",
      "competitors-others_positive ---> competitors-others --> positive\n",
      "competitors_negative ---> competitors --> negative\n",
      "competitors_positive ---> competitors --> positive\n",
      "complementary_negative ---> complementary --> negative\n",
      "complementary_positive ---> complementary --> positive\n",
      "customer-care_negative ---> customer-care --> negative\n",
      "customer-care_positive ---> customer-care --> positive\n",
      "deals-offers_negative ---> deals-offers --> negative\n",
      "deals-offers_positive ---> deals-offers --> positive\n",
      "death_negative ---> death --> negative\n",
      "death_positive ---> death --> positive\n",
      "delivery-charges-old_negative ---> delivery-charges --> negative\n",
      "delivery-charges-old_positive ---> delivery-charges --> positive\n",
      "delivery-charges_negative ---> delivery-charges --> negative\n",
      "delivery-charges_positive ---> delivery-charges --> positive\n",
      "delivery-executive-old_negative ---> delivery-executive --> negative\n",
      "delivery-executive-old_positive ---> delivery-executive --> positive\n",
      "delivery-executive_negative ---> delivery-executive --> negative\n",
      "delivery-executive_positive ---> delivery-executive --> positive\n",
      "delivery-old_negative ---> delivery --> negative\n",
      "delivery-old_positive ---> delivery --> positive\n",
      "delivery_negative ---> delivery --> negative\n",
      "delivery_positive ---> delivery --> positive\n",
      "dental-health_negative ---> dental-health --> negative\n",
      "dental-health_positive ---> dental-health --> positive\n",
      "display-image_negative ---> display-image --> negative\n",
      "display-image_positive ---> display-image --> positive\n",
      "dog-user-breed_negative ---> dog-user-breed --> negative\n",
      "dog-user-breed_positive ---> dog-user-breed --> positive\n",
      "ease-of-intake_negative ---> ease-of-intake --> negative\n",
      "ease-of-intake_positive ---> ease-of-intake --> positive\n",
      "effect-on-stomach_negative ---> effect-on-stomach --> negative\n",
      "effect-on-stomach_positive ---> effect-on-stomach --> positive\n",
      "etailers-old_negative ---> etailers --> negative\n",
      "etailers-old_positive ---> etailers --> positive\n",
      "etailers_negative ---> etailers --> negative\n",
      "etailers_positive ---> etailers --> positive\n",
      "feedback-request-3stars_negative ---> feedback-request-3stars --> negative\n",
      "feedback-request-4stars_negative ---> feedback-request-4stars --> negative\n",
      "feedback-request_negative ---> feedback-request --> negative\n",
      "feedback-thanks_negative ---> feedback-thanks --> negative\n",
      "feedback-thanks_positive ---> feedback-thanks --> positive\n",
      "food-condition_negative ---> food-condition --> negative\n",
      "food-condition_positive ---> food-condition --> positive\n",
      "food-eatability_negative ---> food-eatability --> negative\n",
      "food-eatability_positive ---> food-eatability --> positive\n",
      "food-ingredients_negative ---> food-ingredients --> negative\n",
      "food-ingredients_positive ---> food-ingredients --> positive\n",
      "food-quality_negative ---> food-quality --> negative\n",
      "food-quality_positive ---> food-quality --> positive\n",
      "food-shapes_negative ---> food-shapes --> negative\n",
      "food-shapes_positive ---> food-shapes --> positive\n",
      "food-type_negative ---> food-type --> negative\n",
      "food-type_positive ---> food-type --> positive\n",
      "health-allergy_negative ---> health-allergy --> negative\n",
      "health-allergy_positive ---> health-allergy --> positive\n",
      "health-ill_negative ---> health-ill --> negative\n",
      "health-ill_positive ---> health-ill --> positive\n",
      "health-toxic_negative ---> health-toxic --> negative\n",
      "health-toxic_positive ---> health-toxic --> positive\n",
      "health-vomit_negative ---> health-vomit --> negative\n",
      "health-vomit_positive ---> health-vomit --> positive\n",
      "health_negative ---> health --> negative\n",
      "health_positive ---> health --> positive\n",
      "hot-clusters_negative ---> hot-clusters --> negative\n",
      "infested-food_negative ---> infested-food --> negative\n",
      "infested-food_positive ---> infested-food --> positive\n",
      "invoice-old_negative ---> invoice --> negative\n",
      "invoice-old_positive ---> invoice --> positive\n",
      "invoice_negative ---> invoice --> negative\n",
      "invoice_positive ---> invoice --> positive\n",
      "likability_negative ---> likability --> negative\n",
      "likability_positive ---> likability --> positive\n",
      "nutritional-information_negative ---> nutritional-information --> negative\n",
      "nutritional-information_positive ---> nutritional-information --> positive\n",
      "opinion-old_negative ---> opinion --> negative\n",
      "opinion-old_positive ---> opinion --> positive\n",
      "opinion_negative ---> opinion --> negative\n",
      "opinion_positive ---> opinion --> positive\n",
      "oral-health_negative ---> oral-health --> negative\n",
      "oral-health_positive ---> oral-health --> positive\n",
      "packaging-old_negative ---> packaging --> negative\n",
      "packaging-old_positive ---> packaging --> positive\n",
      "packaging_negative ---> packaging --> negative\n",
      "packaging_positive ---> packaging --> positive\n",
      "price_negative ---> price --> negative\n",
      "price_positive ---> price --> positive\n",
      "product-condition-damaged-old_negative ---> product-condition-damaged --> negative\n",
      "product-condition-damaged-old_positive ---> product-condition-damaged --> positive\n",
      "product-condition-damaged_negative ---> product-condition-damaged --> negative\n",
      "product-condition-damaged_positive ---> product-condition-damaged --> positive\n",
      "product-condition-old_negative ---> product-condition --> negative\n",
      "product-condition-old_positive ---> product-condition --> positive\n",
      "product-condition_negative ---> product-condition --> negative\n",
      "product-condition_positive ---> product-condition --> positive\n",
      "product-dimensions_negative ---> product-dimensions --> negative\n",
      "product-dimensions_positive ---> product-dimensions --> positive\n",
      "product-duplicate_negative ---> product-duplicate --> negative\n",
      "product-duplicate_positive ---> product-duplicate --> positive\n",
      "product-durability_negative ---> product-durability --> negative\n",
      "product-durability_positive ---> product-durability --> positive\n",
      "product-overall-5stars_positive ---> product-overall-5stars --> positive\n",
      "product-overall-long-reply-3-stars_positive ---> product-overall-long-reply-3-stars --> positive\n",
      "product-overall-long-reply-4-stars_positive ---> product-overall-long-reply-4-stars --> positive\n",
      "product-overall-long-reply-old_negative ---> product-overall-long-reply --> negative\n",
      "product-overall-long-reply_negative ---> product-overall-long-reply --> negative\n",
      "product-overall-longer-reply-3-stars_positive ---> product-overall-longer-reply-3-stars --> positive\n",
      "product-overall-longer-reply-4-stars_positive ---> product-overall-longer-reply-4-stars --> positive\n",
      "product-overall-old_negative ---> product-overall --> negative\n",
      "product-overall-old_positive ---> product-overall --> positive\n",
      "product-overall-short-reply-old_negative ---> product-overall-short-reply --> negative\n",
      "product-overall-short-reply_negative ---> product-overall-short-reply --> negative\n",
      "product-overall_negative ---> product-overall --> negative\n",
      "product-overall_positive ---> product-overall --> positive\n",
      "replacement-old_negative ---> replacement --> negative\n",
      "replacement-old_positive ---> replacement --> positive\n",
      "replacement_negative ---> replacement --> negative\n",
      "replacement_positive ---> replacement --> positive\n",
      "seller-old_negative ---> seller --> negative\n",
      "seller-old_positive ---> seller --> positive\n",
      "seller_negative ---> seller --> negative\n",
      "seller_positive ---> seller --> positive\n",
      "service-old_negative ---> service --> negative\n",
      "service-old_positive ---> service --> positive\n",
      "service_negative ---> service --> negative\n",
      "service_positive ---> service --> positive\n",
      "share-details_positive ---> share-details --> positive\n",
      "smell_negative ---> smell --> negative\n",
      "smell_positive ---> smell --> positive\n",
      "taste_negative ---> taste --> negative\n",
      "taste_positive ---> taste --> positive\n",
      "texture-style_negative ---> texture-style --> negative\n",
      "texture-style_positive ---> texture-style --> positive\n",
      "vfm_negative ---> vfm --> negative\n",
      "vfm_positive ---> vfm --> positive\n",
      "warranty-old_negative ---> warranty --> negative\n",
      "warranty-old_positive ---> warranty --> positive\n",
      "warranty_negative ---> warranty --> negative\n",
      "warranty_positive ---> warranty --> positive\n"
     ]
    }
   ],
   "source": [
    "asp = []\n",
    "for file in glob.glob(replies_dir+'/*.txt'):\n",
    "    name = file.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    asp_name = name.split('_')[0].replace('-old','')\n",
    "    \n",
    "    sent  = name.split('_')[-1].split('.')[0]\n",
    "    print name,'--->',asp_name,'-->',sent\n",
    "    f = open(file,'rb')\n",
    "    lines =f.readlines()\n",
    "    lines = [words for segments in lines for words in segments.replace('\\n','').split('\\r')]\n",
    "    lines = filter(None, lines)\n",
    "    for line in lines:\n",
    "        if asp_name.strip() in fd and sent == 'negative' :\n",
    "            row = ['',asp_name,sent,line.strip(),'DR']\n",
    "            asp.append(row)\n",
    "        else:\n",
    "            row = ['',asp_name,sent,line.strip(),'R']\n",
    "            asp.append(row)\n",
    "asp = pd.DataFrame(asp)\n",
    "asp.columns = ['brand','aspect','sentiment','template_response','status']\n",
    "asp = asp[asp.template_response != '.']\n",
    "asp.to_csv('response_templates.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asp.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions_words_initial\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for i in glob.glob('Pedigree_autoresponses/*.txt'):\n",
    "    a = i.replace(\"Pedigree_autoresponses/\",\"\").split('.txt')[0]\n",
    "    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp ={}\n",
    "asp['x'] = [1,2,3,4]\n",
    "asp['xy'] = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "for i in asp:\n",
    "    print asp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
